{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from implementations_clean import *\n",
    "from proj1_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,X,ids = load_csv_data(\"train.csv\")\n",
    "#ADD BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.91</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>197.760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>258.733</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>125.157</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.916</td>\n",
       "      <td>164.546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>197.814</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.186</td>\n",
       "      <td>260.414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.251</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>75.968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060</td>\n",
       "      <td>86.062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>57.983</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>53.131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1        2       3     4        5      6      7       8   \\\n",
       "0  138.470   51.655   97.827  27.980  0.91  124.711  2.666  3.064  41.928   \n",
       "1  160.937   68.768  103.235  48.146   NaN      NaN    NaN  3.473   2.078   \n",
       "2      NaN  162.172  125.953  35.635   NaN      NaN    NaN  3.148   9.336   \n",
       "3  143.905   81.417   80.943   0.414   NaN      NaN    NaN  3.310   0.414   \n",
       "4  175.864   16.915  134.805  16.405   NaN      NaN    NaN  3.891  16.405   \n",
       "\n",
       "        9   ...     20       21   22      23     24     25      26    27  \\\n",
       "0  197.760  ... -0.277  258.733  2.0  67.435  2.150  0.444  46.062  1.24   \n",
       "1  125.157  ... -1.916  164.546  1.0  46.226  0.725  1.158     NaN   NaN   \n",
       "2  197.814  ... -2.186  260.414  1.0  44.251  2.053 -2.028     NaN   NaN   \n",
       "3   75.968  ...  0.060   86.062  0.0     NaN    NaN    NaN     NaN   NaN   \n",
       "4   57.983  ... -0.871   53.131  0.0     NaN    NaN    NaN     NaN   NaN   \n",
       "\n",
       "      28       29  \n",
       "0 -2.475  113.497  \n",
       "1    NaN   46.226  \n",
       "2    NaN   44.251  \n",
       "3    NaN    0.000  \n",
       "4    NaN    0.000  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X = np.where(X == -999., np.nan, X)\n",
    "df = pd.DataFrame(X)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1387578679999997"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature 1: correlations der_mass_MMC\n",
    "col_means = np.nanmean(X, axis=0)\n",
    "idxs = np.where(np.isnan(X))\n",
    "X[idxs] = np.take(col_means, idxs[1])\n",
    "X_gt_mmc = np.array(X[:,0], copy=True)\n",
    "X_gt_mmc[X_gt_mmc <= 140] = 140\n",
    "# X = np.column_stack((X, X_gt_mmc))\n",
    "X[:,0][X[:,0] > 140] = 140\n",
    "X = np.column_stack((X, X_gt_mmc))\n",
    "\n",
    "#feature 2: add momentums\n",
    "#tau momentum\n",
    "tau_px = X[:,13]*np.cos(X[:,15])\n",
    "tau_py = X[:,13]*np.sin(X[:,15])\n",
    "tau_pz = X[:,13]*np.sinh(X[:,14])\n",
    "X = np.column_stack((X, tau_px,tau_py,tau_pz))\n",
    "#lep momentum\n",
    "lep_px = X[:,16]*np.cos(X[:,18])\n",
    "lep_py = X[:,16]*np.cos(X[:,18])\n",
    "lep_pz = X[:,16]*np.cos(X[:,17])\n",
    "X = np.column_stack((X, lep_px,lep_py,lep_pz))\n",
    "#leading jet momentum\n",
    "jet_px = X[:,22]*np.cos(X[:,24])\n",
    "jet_py = X[:,22]*np.cos(X[:,24])\n",
    "jet_pz = X[:,22]*np.cos(X[:,23])\n",
    "X = np.column_stack((X, jet_px,jet_py,jet_pz))\n",
    "#subleading jet momentum\n",
    "subjet_px = X[:,25]*np.cos(X[:,27])\n",
    "subjet_py = X[:,25]*np.cos(X[:,27])\n",
    "subjet_pz = X[:,25]*np.cos(X[:,26])\n",
    "X = np.column_stack((X, subjet_px,subjet_py,subjet_pz))\n",
    "\n",
    "# feature 3: abs angles\n",
    "#der_met_phi_centrality\n",
    "X[:,11] = np.abs(X[:,11])\n",
    "#tau phi\n",
    "X[:,15] = np.abs(X[:,15])\n",
    "#lep phi\n",
    "X[:,18] = np.abs(X[:,18])\n",
    "#met phi\n",
    "X[:,20] = np.abs(X[:,20])\n",
    "#lead jet phi\n",
    "X[:,24] = np.abs(X[:,24])\n",
    "#sublead jet phi\n",
    "X[:,27] = np.abs(X[:,27])\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df.head(20)\n",
    "X[:,11].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,11].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(X):\n",
    "    # converting -999. to nan to use np.nanmean and np.nanstd\n",
    "    X = np.where(X == -999., np.nan, X)\n",
    "    # standardizing the data Xd = (X_d - E[X_d])/(std(X_d))\n",
    "    X, means, stds = standardize(X)\n",
    "    # since data is standirdized, the mean is more or less 0 for each feature so replacing by zero is reasonable and helps computations\n",
    "    X = np.where(np.isnan(X), 0, X)\n",
    "    # adding the 1 padding\n",
    "    return np.column_stack((np.ones(X.shape[0]), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,_,_ = standardize(X)\n",
    "# bias = np.ones((X.shape[0],1))\n",
    "# X = np.hstack([bias,X])\n",
    "X = make_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.099192</td>\n",
       "      <td>0.068332</td>\n",
       "      <td>0.407680</td>\n",
       "      <td>-0.469966</td>\n",
       "      <td>-1.591638e+00</td>\n",
       "      <td>-1.153306e+00</td>\n",
       "      <td>1.806346e+00</td>\n",
       "      <td>0.882478</td>\n",
       "      <td>1.033099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480884</td>\n",
       "      <td>-1.047625</td>\n",
       "      <td>-1.047625</td>\n",
       "      <td>-1.767430</td>\n",
       "      <td>-1.267320</td>\n",
       "      <td>-1.267320</td>\n",
       "      <td>-0.238641</td>\n",
       "      <td>0.122568</td>\n",
       "      <td>0.122568</td>\n",
       "      <td>-0.256095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.162178</td>\n",
       "      <td>0.552505</td>\n",
       "      <td>0.540136</td>\n",
       "      <td>-0.153167</td>\n",
       "      <td>-7.229012e-12</td>\n",
       "      <td>-6.304978e-12</td>\n",
       "      <td>6.751165e-13</td>\n",
       "      <td>1.404888</td>\n",
       "      <td>-0.756027</td>\n",
       "      <td>...</td>\n",
       "      <td>1.922023</td>\n",
       "      <td>0.997382</td>\n",
       "      <td>0.997382</td>\n",
       "      <td>0.463829</td>\n",
       "      <td>0.645996</td>\n",
       "      <td>0.645996</td>\n",
       "      <td>-0.652951</td>\n",
       "      <td>0.945345</td>\n",
       "      <td>0.945345</td>\n",
       "      <td>0.614340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.415335</td>\n",
       "      <td>3.195156</td>\n",
       "      <td>1.096560</td>\n",
       "      <td>-0.349710</td>\n",
       "      <td>-7.229012e-12</td>\n",
       "      <td>-6.304978e-12</td>\n",
       "      <td>6.751165e-13</td>\n",
       "      <td>0.989770</td>\n",
       "      <td>-0.430168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289035</td>\n",
       "      <td>1.635168</td>\n",
       "      <td>1.635168</td>\n",
       "      <td>1.751947</td>\n",
       "      <td>-0.612340</td>\n",
       "      <td>-0.612340</td>\n",
       "      <td>0.970068</td>\n",
       "      <td>-1.640389</td>\n",
       "      <td>-1.640389</td>\n",
       "      <td>-1.050357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.162178</td>\n",
       "      <td>0.910379</td>\n",
       "      <td>-0.005853</td>\n",
       "      <td>-0.903016</td>\n",
       "      <td>-7.229012e-12</td>\n",
       "      <td>-6.304978e-12</td>\n",
       "      <td>6.751165e-13</td>\n",
       "      <td>1.196690</td>\n",
       "      <td>-0.830735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.681156</td>\n",
       "      <td>-1.447571</td>\n",
       "      <td>-1.447571</td>\n",
       "      <td>0.933633</td>\n",
       "      <td>-0.130971</td>\n",
       "      <td>-0.130971</td>\n",
       "      <td>-0.015695</td>\n",
       "      <td>-0.004537</td>\n",
       "      <td>-0.004537</td>\n",
       "      <td>0.002805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.162178</td>\n",
       "      <td>-0.914556</td>\n",
       "      <td>1.313369</td>\n",
       "      <td>-0.651804</td>\n",
       "      <td>-7.229012e-12</td>\n",
       "      <td>-6.304978e-12</td>\n",
       "      <td>6.751165e-13</td>\n",
       "      <td>1.938794</td>\n",
       "      <td>-0.112795</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.504646</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.070223</td>\n",
       "      <td>-0.130971</td>\n",
       "      <td>-0.130971</td>\n",
       "      <td>-0.015695</td>\n",
       "      <td>-0.004537</td>\n",
       "      <td>-0.004537</td>\n",
       "      <td>0.002805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4             5             6   \\\n",
       "0  1.0  1.099192  0.068332  0.407680 -0.469966 -1.591638e+00 -1.153306e+00   \n",
       "1  1.0  1.162178  0.552505  0.540136 -0.153167 -7.229012e-12 -6.304978e-12   \n",
       "2  1.0  0.415335  3.195156  1.096560 -0.349710 -7.229012e-12 -6.304978e-12   \n",
       "3  1.0  1.162178  0.910379 -0.005853 -0.903016 -7.229012e-12 -6.304978e-12   \n",
       "4  1.0  1.162178 -0.914556  1.313369 -0.651804 -7.229012e-12 -6.304978e-12   \n",
       "\n",
       "             7         8         9   ...        34        35        36  \\\n",
       "0  1.806346e+00  0.882478  1.033099  ...  0.480884 -1.047625 -1.047625   \n",
       "1  6.751165e-13  1.404888 -0.756027  ...  1.922023  0.997382  0.997382   \n",
       "2  6.751165e-13  0.989770 -0.430168  ... -0.289035  1.635168  1.635168   \n",
       "3  6.751165e-13  1.196690 -0.830735  ... -0.681156 -1.447571 -1.447571   \n",
       "4  6.751165e-13  1.938794 -0.112795  ... -1.504646  0.001200  0.001200   \n",
       "\n",
       "         37        38        39        40        41        42        43  \n",
       "0 -1.767430 -1.267320 -1.267320 -0.238641  0.122568  0.122568 -0.256095  \n",
       "1  0.463829  0.645996  0.645996 -0.652951  0.945345  0.945345  0.614340  \n",
       "2  1.751947 -0.612340 -0.612340  0.970068 -1.640389 -1.640389 -1.050357  \n",
       "3  0.933633 -0.130971 -0.130971 -0.015695 -0.004537 -0.004537  0.002805  \n",
       "4  0.070223 -0.130971 -0.130971 -0.015695 -0.004537 -0.004537  0.002805  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(X)\n",
    "cutoff = int(0.8*((X.shape)[0]))\n",
    "X_train = X[:cutoff]\n",
    "y_train = y[:cutoff]\n",
    "X_test = X[cutoff:]\n",
    "y_test = y[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(X.shape[1])\n",
    "# initial_w = np.random.normal(scale = 0.1, size = X.shape[1])\n",
    "# max_iters = 10*200000\n",
    "max_iters = 1000\n",
    "gamma = 0.1\n",
    "lambda_ = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(initial_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:    \n",
    "    #activations: 'relu', 'sigmoid', 'linear'\n",
    "    #loss assumed to be BCE\n",
    "    def __init__(self, lambda_ = 0.001,  dimensions = [2,10,1], activations = ['relu','sigmoid'] ,weight_decay = 0):\n",
    "        assert (len(dimensions)-1) == len(activations), \"Number of dimensions and activation functions do not match\"\n",
    "        # number of layers of our MLP\n",
    "        self.num_layers = len(dimensions)\n",
    "        self.lambda_ = lambda_\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # initialize the weights\n",
    "        self.weights = {}\n",
    "        self.bias = {}\n",
    "        # the first layer is the input data\n",
    "        self.activations = {}\n",
    "        self.activations_grad = {}\n",
    "        \n",
    "        for n in np.arange(self.num_layers - 1):\n",
    "            # the weights are initialized acccording to a normal distribution and divided by the size of the layer they're on\n",
    "            self.weights[n + 1] = np.random.randn(dimensions[n + 1],dimensions[n]) / np.sqrt(dimensions[n])\n",
    "            # bias are all initialized to zero\n",
    "            self.bias[n + 1] = np.zeros(dimensions[n + 1])\n",
    "            \n",
    "            if activations[n] == 'relu':\n",
    "                self.activations[n+1] = self.relu\n",
    "                self.activations_grad[n+1] = self.relu_gradient\n",
    "            elif activations[n] == 'sigmoid':\n",
    "                self.activations[n+1] = self.sigmoid\n",
    "                self.activations_grad[n+1] = self.sigmoid_gradient\n",
    "            else:\n",
    "                self.activations[n+1] = lambda x : x\n",
    "                self.activations_grad[n+1] = lambda x : 1\n",
    "    \n",
    "    def feed_forward(self, x):        \n",
    "        # keep track of all z and a to compute gradient in the backpropagation\n",
    "        z = {}\n",
    "        # the first layer is the input data\n",
    "        a = {1:x}\n",
    "        # We compute z[n+1] = a[n] * w[n] + b[n]\n",
    "        # and a[n+1] = f(z[n+1]) = f(a[n] * x[n] + b[n]) where * is the inner product\n",
    "        for n in np.arange(1, self.num_layers):\n",
    "            z[n + 1] = self.weights[n] @ a[n] + self.bias[n]\n",
    "            a[n + 1] = self.activations[n](z[n + 1])\n",
    "\n",
    "        y_pred = a[n+1]    \n",
    "        return y_pred,a, z\n",
    "    \n",
    "    # returns a prediction\n",
    "    def predict(self, X):\n",
    "        preds = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            y_i_proba,_,_ = self.feed_forward(X[i].squeeze()) \n",
    "            preds[i] = (y_i_proba > 0.5)\n",
    "        return preds\n",
    "    \n",
    "    def back_propagate(self, y,y_pred, a, z):\n",
    "        \n",
    "        weights_gradient = {}\n",
    "        bias_gradient = {}\n",
    "        \n",
    "        nabla = self.BCE_gradient(y,y_pred)\n",
    "        \n",
    "        for n in np.flip(np.arange(1, self.num_layers)):\n",
    "            nabla = nabla * self.activations_grad[n](z[n+1])\n",
    "            weights_gradient[n] = np.outer(nabla, a[n])\n",
    "            bias_gradient[n] = nabla\n",
    "            nabla = nabla @ self.weights[n]\n",
    "        \n",
    "        return weights_gradient, bias_gradient\n",
    "        ## self.gradient_descent_step(weights_gradient, bias_gradient)\n",
    "    \n",
    "    #weight decay : l2 reg\n",
    "    def gradient_descent_step(self, weights_gradient, bias_gradient):\n",
    "        for n in np.arange(1, self.num_layers):\n",
    "            self.weights[n] = self.weights[n] - self.lambda_ * (weights_gradient[n] + self.weight_decay*self.weights[n])\n",
    "            self.bias[n] = self.bias[n] - self.lambda_ * (bias_gradient[n] + self.weight_decay*self.bias[n])            \n",
    "    \n",
    "    #batch size = 1 for now\n",
    "    def train(self, X, y, max_iter, batch_size = 1):\n",
    "        for i in np.arange(max_iter):\n",
    "            idxs = np.random.randint(0, X.shape[0],batch_size)\n",
    "            X_batch = X[idxs].squeeze()\n",
    "            y_batch = y[idxs]\n",
    "            y_pred,a, z = self.feed_forward(X_batch)\n",
    "            weights_gradient, bias_gradient = self.back_propagate(y_batch,y_pred,a, z)\n",
    "            self.gradient_descent_step(weights_gradient, bias_gradient)\n",
    "            if (i % 20000 == 0):\n",
    "                loss = self.BCE_loss(X,y)\n",
    "                print(\"Iteration : {}, loss : {}\".format(i,loss))\n",
    "        loss = self.BCE_loss(X,y)\n",
    "        return loss\n",
    "            \n",
    "    def sigmoid(self,z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_gradient(self,z):\n",
    "        return sigmoid(z) * (1 - sigmoid(z))\n",
    "    \n",
    "    def relu(self,z):\n",
    "        return np.where(z < 0, 0, z)\n",
    "\n",
    "    def relu_gradient(self, z):\n",
    "        return np.where(z < 0, 0, 1)\n",
    "        \n",
    "    #check if possible to vectorize\n",
    "    def BCE_loss(self,X, y):\n",
    "        loss = 0\n",
    "        N = len(y)\n",
    "        for i in range(N):\n",
    "            y_pred,_,_ = self.feed_forward(X[i])\n",
    "            eps = 1e-7\n",
    "            loss_i = -(y[i]*np.log(y_pred+eps) + (1-y[i])*np.log(1-y_pred+eps))\n",
    "            loss = loss + loss_i/N\n",
    "        return loss\n",
    "    \n",
    "    def BCE_gradient(self,y,y_pred):\n",
    "        return y_pred-y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = X_train.shape[1]\n",
    "n_h1 = 30\n",
    "n_h2 = 30\n",
    "n_h3 = 30\n",
    "out_dim = 1\n",
    "dimensions = [in_dim, n_h1,n_h2,n_h3,out_dim]\n",
    "activations = ['relu','relu','relu','sigmoid']\n",
    "lambda_ = 0.001\n",
    "weight_decay = 0.001\n",
    "mlp = MLP(lambda_ = lambda_, dimensions = dimensions, activations = activations, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0, loss : [0.69343176]\n",
      "Iteration : 20000, loss : [0.60435843]\n",
      "Iteration : 40000, loss : [0.54242346]\n",
      "Iteration : 60000, loss : [0.49945692]\n",
      "Iteration : 80000, loss : [0.4737464]\n",
      "Iteration : 100000, loss : [0.458027]\n",
      "Iteration : 120000, loss : [0.44807639]\n",
      "Iteration : 140000, loss : [0.44005671]\n",
      "Iteration : 160000, loss : [0.43482565]\n",
      "Iteration : 180000, loss : [0.4295358]\n",
      "Iteration : 200000, loss : [0.42624138]\n",
      "Iteration : 220000, loss : [0.42517266]\n",
      "Iteration : 240000, loss : [0.42091084]\n",
      "Iteration : 260000, loss : [0.41851955]\n",
      "Iteration : 280000, loss : [0.41664192]\n",
      "Iteration : 300000, loss : [0.41479273]\n",
      "Iteration : 320000, loss : [0.41445563]\n",
      "Iteration : 340000, loss : [0.41238866]\n",
      "Iteration : 360000, loss : [0.41043469]\n",
      "Iteration : 380000, loss : [0.40930556]\n",
      "Iteration : 400000, loss : [0.40959233]\n",
      "Iteration : 420000, loss : [0.407504]\n",
      "Iteration : 440000, loss : [0.40601818]\n",
      "Iteration : 460000, loss : [0.40537264]\n",
      "Iteration : 480000, loss : [0.40482239]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.40427008])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.train(X_train,y_train,max_iter = 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82697\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_train)\n",
    "acc = 1-np.sum(np.abs(y_pred - y_train)) / X_train.shape[0]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82718\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "acc = 1-np.sum(np.abs(y_pred - y_test)) / X_test.shape[0]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loss,w = GD_logistic_regression(y = y_train, tx = X_train, initial_w = initial_w,\n",
    "# #                              max_iters = max_iters, gamma = gamma)\n",
    "# loss,w = GD_reg_logistic_regression(y = y_train, tx = X_train, initial_w = initial_w,\n",
    "#                              max_iters = max_iters, gamma = gamma, lambda_ = lambda_)\n",
    "# # loss,w = logistic_regression(y = y_train, tx = X_train, initial_w = initial_w,\n",
    "# #                              max_iters = max_iters, gamma = gamma)\n",
    "# # loss,w = least_squares_GD(y = y_train,tx = X_train, initial_w = initial_w, max_iters = max_iters, gamma = gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train accuracy\n",
    "# y_pred = classification(X_train @ w)\n",
    "# acc = 1-np.sum(np.abs(y_pred - y_train)) / X_train.shape[0]\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test accuracy\n",
    "# y_pred = classification(X_test @ w)\n",
    "# acc = 1-np.sum(np.abs(y_pred - y_test)) / X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,X_sub,ids = load_csv_data(\"test.csv\")\n",
    "#feature 1: correlations der_mass_MMC\n",
    "col_means = np.nanmean(X_sub, axis=0)\n",
    "idxs = np.where(np.isnan(X_sub))\n",
    "X_sub[idxs] = np.take(col_means, idxs[1])\n",
    "X_gt_mmc = np.array(X_sub[:,0], copy=True)\n",
    "X_gt_mmc[X_gt_mmc <= 140] = 140\n",
    "# X = np.column_stack((X, X_gt_mmc))\n",
    "X_sub[:,0][X_sub[:,0] > 140] = 140\n",
    "X_sub = np.column_stack((X_sub, X_gt_mmc))\n",
    "\n",
    "#feature 2: add momentums\n",
    "#tau momentum\n",
    "tau_px = X_sub[:,13]*np.cos(X_sub[:,15])\n",
    "tau_py = X_sub[:,13]*np.sin(X_sub[:,15])\n",
    "tau_pz = X_sub[:,13]*np.sinh(X_sub[:,14])\n",
    "X_sub = np.column_stack((X_sub, tau_px,tau_py,tau_pz))\n",
    "#lep momentum\n",
    "lep_px = X_sub[:,16]*np.cos(X_sub[:,18])\n",
    "lep_py = X_sub[:,16]*np.cos(X_sub[:,18])\n",
    "lep_pz = X_sub[:,16]*np.cos(X_sub[:,17])\n",
    "X_sub = np.column_stack((X_sub, lep_px,lep_py,lep_pz))\n",
    "#leading jet momentum\n",
    "jet_px = X_sub[:,22]*np.cos(X_sub[:,24])\n",
    "jet_py = X_sub[:,22]*np.cos(X_sub[:,24])\n",
    "jet_pz = X_sub[:,22]*np.cos(X_sub[:,23])\n",
    "X_sub = np.column_stack((X_sub, jet_px,jet_py,jet_pz))\n",
    "#subleading jet momentum\n",
    "subjet_px = X_sub[:,25]*np.cos(X_sub[:,27])\n",
    "subjet_py = X_sub[:,25]*np.cos(X_sub[:,27])\n",
    "subjet_pz = X_sub[:,25]*np.cos(X_sub[:,26])\n",
    "X_sub = np.column_stack((X_sub, subjet_px,subjet_py,subjet_pz))\n",
    "\n",
    "# feature 3: abs angles\n",
    "#der_met_phi_centrality\n",
    "X_sub[:,11] = np.abs(X_sub[:,11])\n",
    "#tau phi\n",
    "X_sub[:,15] = np.abs(X_sub[:,15])\n",
    "#lep phi\n",
    "X_sub[:,18] = np.abs(X_sub[:,18])\n",
    "#met phi\n",
    "X_sub[:,20] = np.abs(X_sub[:,20])\n",
    "#lead jet phi\n",
    "X_sub[:,24] = np.abs(X_sub[:,24])\n",
    "#sublead jet phi\n",
    "X_sub[:,27] = np.abs(X_sub[:,27])\n",
    "\n",
    "X_sub = make_features(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_pred = predict_labels(w,X_sub) \n",
    "sub_pred = mlp.predict(X_sub)\n",
    "#map to -1,1\n",
    "sub_pred = sub_pred*2 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3404312981532386"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids, sub_pred, \"submission_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv(\"submission_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.to_csv(\"submission_test.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
